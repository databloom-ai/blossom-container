{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# WordCount Example\n",
    "\n",
    "In this WordCount Example our goal is:\n",
    "\n",
    "&emsp; Take a first look at the Wayang API in a short program\n",
    "- Wayang API is similar to Spark API\n",
    "- It does not require \"a steep learning curve\"\n",
    "\n",
    "&emsp; Show the provided abstraction on top of Big Data platforms\n",
    "- Single data analytics task can run on any platform \n",
    "- Potentially substasks can run in different platforms if the task could take advantage of it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Preparing dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  Importing the needs libraries for the exections, this are comming from the maven instalation perfomed in the step 0 -->\n",
    "\n",
    "<!-- > This step imports the necessary libraries for subsequent program executions.\n",
    "All these packages come from the previous Maven Instalation -->\n",
    "This step imports the required modules to execute the code. All these packages come from the previous Maven Instalation\n",
    "\n",
    "The imported libraries are:\n",
    "\n",
    "Module | Java's | Scala's | Description\n",
    ":----- | -------------: | --------------: | :----------\n",
    "wayang-core | 8, 11 | 2.11, 2.12 | provides core data structures and the optimizer (required)\n",
    "wayang-basic | 8, 11 | 2.11, 2.12 | provides common operators and data types for your apps (recommended)\n",
    "wayang-api-scala-java | 8, 11 | 2.11, 2.12 | provides an easy-to-use Scala and Java API to assemble wayang plans (recommended)\n",
    "wayang-java | 8, 11 | 2.11, 2.12 | adapters for [Java Stream](https://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html) processing platforms\n",
    "wayang-spark | 8, 11 | 2.11, 2.12 | adapters for [Apache Spark](https://spark.apache.org) processing platforms\n",
    "wayang-flink | 8, 11 | 2.11, 2.12 | adapters for [Apache Flink](https://flink.apache.org) processing platforms\n",
    "hadoop-common | 8,11 | - | Hadoop-commons is required because the lack of the Environment Variable **HADOOP_HOME**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                              \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                   \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                    \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                     \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                    \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                   \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                      \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/* Import Dependencies */\n",
    "import $ivy.`com.fasterxml.jackson.module:jackson-module-scala_2.12:2.10.2`\n",
    "import $ivy.`com.fasterxml.jackson.core:jackson-databind:2.10.2`\n",
    "import $ivy.`org.apache.wayang:wayang-core:0.7.1`\n",
    "import $ivy.`org.apache.wayang:wayang-basic:0.7.1`\n",
    "import $ivy.`org.apache.wayang:wayang-java:0.7.1`\n",
    "import $ivy.`org.apache.wayang:wayang-api-scala-java_2.12:0.7.1`\n",
    "import $ivy.`org.apache.hadoop:hadoop-common:2.8.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.wayang.api._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.wayang.core.api.{Configuration, WayangContext}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.wayang.core.util.fs.FileSystems\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.wayang.java.Java\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.File;\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/* Include required classes */\n",
    "import org.apache.wayang.api._\n",
    "import org.apache.wayang.core.api.{Configuration, WayangContext}\n",
    "import org.apache.wayang.core.util.fs.FileSystems\n",
    "import org.apache.wayang.java.Java\n",
    "import java.io.File;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordcount program - Platform Agnostic\n",
    "\n",
    "- Plan Builder works as a utility to build and execute Wayang Plans \n",
    "- A Wayang Plan consists of a set of operators with dependencies between them\n",
    "- The provided logical plan is independent of any underlying platform to use\n",
    "> Wayang engine receives the user-defined Wayang plan and runs an optimization process to transform this plan consisting of logical operators to an execution plan consisting of a set of physical operators executable by specific platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mwordcount\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wordcount(context: WayangContext) = {\n",
    "    val planBuilder = new PlanBuilder(context)\n",
    "    \n",
    "    val inputFile = new File(\"book.txt\").toURI().toString()\n",
    "    \n",
    "    planBuilder\n",
    "      .withJobName(s\"WordCount ($inputFile)\")\n",
    "      .readTextFile(inputFile)\n",
    "      .flatMap(_.split(\"\\\\W+\"))\n",
    "      .filter(_.nonEmpty)\n",
    "      .map(word => (word.toLowerCase, 1))\n",
    "      .reduceByKey(_._1, (c1, c2) => (c1._1, c1._2 + c2._2))\n",
    "      .collect()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing WordCount in Java via Wayang Context \n",
    "\n",
    "Wayang Context is the entry point for users to work with Wayang. It allows to declare explicitly an execution Platform on which the code will run.\n",
    "\n",
    "- The object Java.basicPlugin enables to Wayang to use operators of the Java Platform\n",
    "\n",
    "> WayangContext also manages the Job creation and its execution as Wayang Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcontext\u001b[39m: \u001b[32mWayangContext\u001b[39m = org.apache.wayang.core.api.WayangContext@1ce20511"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val context = new WayangContext().withPlugin(Java.basicPlugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedText\">\n",
       "<pre><code><span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">result</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">Iterable</span></span>[(<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">Int</span></span>)] = <span style=\"color: yellow\"><span class=\"ansi-yellow-fg\">Buffer</span></span>(\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;tears&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;scheme&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;bells&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;father&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;why&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;body&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;upon&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;parturition&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;boar&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;currents&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;that&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">3</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;not&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">2</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;his&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;and&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">5</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;said&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;you&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;hours&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;scaling&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;living&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;qu&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;this&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">3</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;them&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;entered&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;strangers&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;an&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;the&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">3</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;artificial&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;what&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;well&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;to&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">3</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;he&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;wind&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>)\n",
       ")</code></pre>\n",
       "</div>"
      ],
      "text/plain": [
       "\u001b[36mresult\u001b[39m: \u001b[32mIterable\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mInt\u001b[39m)] = \u001b[33mBuffer\u001b[39m(\n",
       "  (\u001b[32m\"tears\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"scheme\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"bells\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"father\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"why\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"body\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"upon\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"parturition\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"boar\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"currents\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"that\"\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  (\u001b[32m\"not\"\u001b[39m, \u001b[32m2\u001b[39m),\n",
       "  (\u001b[32m\"his\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"and\"\u001b[39m, \u001b[32m5\u001b[39m),\n",
       "  (\u001b[32m\"said\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"you\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"hours\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"scaling\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"living\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"qu\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"this\"\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  (\u001b[32m\"them\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"entered\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"strangers\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"an\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"the\"\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  (\u001b[32m\"artificial\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"what\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"well\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"to\"\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  (\u001b[32m\"he\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"wind\"\u001b[39m, \u001b[32m1\u001b[39m)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var result = wordcount(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing WordCount in Spark\n",
    "\n",
    "Now, Wayang context we can reassign the target platform\n",
    "\n",
    "- First, add Wayang Spark Module dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                          \u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.wayang:wayang-spark_2.12:0.7.1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then, import the Spark class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.wayang.spark.Spark\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.wayang.spark.Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally, set Wayang context is to work with Spark Platform\n",
    "> There is no need to change the WordCount code at all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcontext\u001b[39m: \u001b[32mWayangContext\u001b[39m = org.apache.wayang.core.api.WayangContext@3c6d9d9a"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val context = new WayangContext().withPlugin(Spark.basicPlugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.7.30/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "24/02/05 15:50:53 INFO SparkContext: Running Spark version 3.1.2\n",
      "24/02/05 15:50:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/02/05 15:50:54 INFO ResourceUtils: ==============================================================\n",
      "24/02/05 15:50:54 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "24/02/05 15:50:54 INFO ResourceUtils: ==============================================================\n",
      "24/02/05 15:50:54 INFO SparkContext: Submitted application: WordCount (file:/home/jovyan/book.txt)\n",
      "24/02/05 15:50:54 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "24/02/05 15:50:54 INFO ResourceProfile: Limiting resource is cpu\n",
      "24/02/05 15:50:54 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "24/02/05 15:50:54 INFO SecurityManager: Changing view acls to: jovyan\n",
      "24/02/05 15:50:54 INFO SecurityManager: Changing modify acls to: jovyan\n",
      "24/02/05 15:50:54 INFO SecurityManager: Changing view acls groups to: \n",
      "24/02/05 15:50:54 INFO SecurityManager: Changing modify acls groups to: \n",
      "24/02/05 15:50:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jovyan); groups with view permissions: Set(); users  with modify permissions: Set(jovyan); groups with modify permissions: Set()\n",
      "24/02/05 15:50:54 INFO Utils: Successfully started service 'sparkDriver' on port 35387.\n",
      "24/02/05 15:50:54 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/02/05 15:50:54 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/02/05 15:50:54 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "24/02/05 15:50:54 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "24/02/05 15:50:54 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/02/05 15:50:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b7eb3e09-5353-48b1-8919-744de684496e\n",
      "24/02/05 15:50:54 INFO MemoryStore: MemoryStore started with capacity 2.1 GiB\n",
      "24/02/05 15:50:54 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "24/02/05 15:50:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "24/02/05 15:50:55 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://80d73ccee89a:4040\n",
      "24/02/05 15:50:55 INFO Executor: Starting executor ID driver on host 80d73ccee89a\n",
      "24/02/05 15:50:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39579.\n",
      "24/02/05 15:50:55 INFO NettyBlockTransferService: Server created on 80d73ccee89a:39579\n",
      "24/02/05 15:50:55 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "24/02/05 15:50:55 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 80d73ccee89a, 39579, None)\n",
      "24/02/05 15:50:55 INFO BlockManagerMasterEndpoint: Registering block manager 80d73ccee89a:39579 with 2.1 GiB RAM, BlockManagerId(driver, 80d73ccee89a, 39579, None)\n",
      "24/02/05 15:50:55 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 80d73ccee89a, 39579, None)\n",
      "24/02/05 15:50:55 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 80d73ccee89a, 39579, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fs.s3.awsAccessKeyId\n",
      "fs.s3.awsSecretAccessKey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/05 15:50:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 127.9 KiB, free 2.1 GiB)\n",
      "24/02/05 15:50:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.1 KiB, free 2.1 GiB)\n",
      "24/02/05 15:50:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 80d73ccee89a:39579 (size: 25.1 KiB, free: 2.1 GiB)\n",
      "24/02/05 15:50:55 INFO SparkContext: Created broadcast 0 from textFile at SparkTextFileSource.java:70\n",
      "24/02/05 15:50:56 INFO SparkContext: Starting job: hasNext at Iterator.java:132\n",
      "24/02/05 15:50:56 INFO FileInputFormat: Total input files to process : 1\n",
      "24/02/05 15:50:56 INFO DAGScheduler: Registering RDD 5 (mapToPair at SparkReduceByOperator.java:95) as input to shuffle 0\n",
      "24/02/05 15:50:56 INFO DAGScheduler: Got job 0 (hasNext at Iterator.java:132) with 1 output partitions\n",
      "24/02/05 15:50:56 INFO DAGScheduler: Final stage: ResultStage 1 (hasNext at Iterator.java:132)\n",
      "24/02/05 15:50:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)\n",
      "24/02/05 15:50:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)\n",
      "24/02/05 15:50:56 INFO DAGScheduler: Submitting ShuffleMapStage 0 (SparkReduceBy[1->1, id=45a2217f] MapPartitionsRDD[5] at mapToPair at SparkReduceByOperator.java:95), which has no missing parents\n",
      "24/02/05 15:50:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 9.2 KiB, free 2.1 GiB)\n",
      "24/02/05 15:50:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 2.1 GiB)\n",
      "24/02/05 15:50:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 80d73ccee89a:39579 (size: 4.7 KiB, free: 2.1 GiB)\n",
      "24/02/05 15:50:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/05 15:50:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (SparkReduceBy[1->1, id=45a2217f] MapPartitionsRDD[5] at mapToPair at SparkReduceByOperator.java:95) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/05 15:50:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "24/02/05 15:50:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (80d73ccee89a, executor driver, partition 0, PROCESS_LOCAL, 4484 bytes) taskResourceAssignments Map()\n",
      "24/02/05 15:50:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "24/02/05 15:50:56 INFO HadoopRDD: Input split: file:/home/jovyan/book.txt:0+237\n",
      "24/02/05 15:50:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1293 bytes result sent to driver\n",
      "24/02/05 15:50:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 327 ms on 80d73ccee89a (executor driver) (1/1)\n",
      "24/02/05 15:50:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "24/02/05 15:50:56 INFO DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkReduceByOperator.java:95) finished in 0.511 s\n",
      "24/02/05 15:50:56 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/02/05 15:50:56 INFO DAGScheduler: running: Set()\n",
      "24/02/05 15:50:56 INFO DAGScheduler: waiting: Set(ResultStage 1)\n",
      "24/02/05 15:50:56 INFO DAGScheduler: failed: Set()\n",
      "24/02/05 15:50:56 INFO DAGScheduler: Submitting ResultStage 1 (SparkReduceBy[1->1, id=45a2217f] MapPartitionsRDD[7] at map at SparkReduceByOperator.java:100), which has no missing parents\n",
      "24/02/05 15:50:56 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.4 KiB, free 2.1 GiB)\n",
      "24/02/05 15:50:56 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 2.1 GiB)\n",
      "24/02/05 15:50:56 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 80d73ccee89a:39579 (size: 2.9 KiB, free: 2.1 GiB)\n",
      "24/02/05 15:50:56 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/05 15:50:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (SparkReduceBy[1->1, id=45a2217f] MapPartitionsRDD[7] at map at SparkReduceByOperator.java:100) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/05 15:50:56 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "24/02/05 15:50:56 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (80d73ccee89a, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/05 15:50:56 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "24/02/05 15:50:57 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/05 15:50:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms\n",
      "24/02/05 15:50:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1527 bytes result sent to driver\n",
      "24/02/05 15:50:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 122 ms on 80d73ccee89a (executor driver) (1/1)\n",
      "24/02/05 15:50:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "24/02/05 15:50:57 INFO DAGScheduler: ResultStage 1 (hasNext at Iterator.java:132) finished in 0.140 s\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/05 15:50:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Job 0 finished: hasNext at Iterator.java:132, took 0.919206 s\n",
      "24/02/05 15:50:57 INFO SparkContext: Starting job: hasNext at Iterator.java:132\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Got job 1 (hasNext at Iterator.java:132) with 1 output partitions\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Final stage: ResultStage 3 (hasNext at Iterator.java:132)\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Submitting ResultStage 3 (SparkReduceBy[1->1, id=45a2217f] MapPartitionsRDD[7] at map at SparkReduceByOperator.java:100), which has no missing parents\n",
      "24/02/05 15:50:57 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 5.4 KiB, free 2.1 GiB)\n",
      "24/02/05 15:50:57 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 2.1 GiB)\n",
      "24/02/05 15:50:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 80d73ccee89a:39579 (size: 2.9 KiB, free: 2.1 GiB)\n",
      "24/02/05 15:50:57 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (SparkReduceBy[1->1, id=45a2217f] MapPartitionsRDD[7] at map at SparkReduceByOperator.java:100) (first 15 tasks are for partitions Vector(1))\n",
      "24/02/05 15:50:57 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0\n",
      "24/02/05 15:50:57 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (80d73ccee89a, executor driver, partition 1, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/05 15:50:57 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)\n",
      "24/02/05 15:50:57 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/05 15:50:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "24/02/05 15:50:57 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 1580 bytes result sent to driver\n",
      "24/02/05 15:50:57 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 26 ms on 80d73ccee89a (executor driver) (1/1)\n",
      "24/02/05 15:50:57 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "24/02/05 15:50:57 INFO DAGScheduler: ResultStage 3 (hasNext at Iterator.java:132) finished in 0.058 s\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/05 15:50:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Job 1 finished: hasNext at Iterator.java:132, took 0.079417 s\n",
      "24/02/05 15:50:57 INFO SparkContext: Starting job: hasNext at Iterator.java:132\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Got job 2 (hasNext at Iterator.java:132) with 1 output partitions\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Final stage: ResultStage 5 (hasNext at Iterator.java:132)\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Submitting ResultStage 5 (SparkReduceBy[1->1, id=45a2217f] MapPartitionsRDD[7] at map at SparkReduceByOperator.java:100), which has no missing parents\n",
      "24/02/05 15:50:57 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 5.4 KiB, free 2.1 GiB)\n",
      "24/02/05 15:50:57 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 2.1 GiB)\n",
      "24/02/05 15:50:57 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 80d73ccee89a:39579 (size: 2.9 KiB, free: 2.1 GiB)\n",
      "24/02/05 15:50:57 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (SparkReduceBy[1->1, id=45a2217f] MapPartitionsRDD[7] at map at SparkReduceByOperator.java:100) (first 15 tasks are for partitions Vector(2))\n",
      "24/02/05 15:50:57 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0\n",
      "24/02/05 15:50:57 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (80d73ccee89a, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/05 15:50:57 INFO Executor: Running task 0.0 in stage 5.0 (TID 3)\n",
      "24/02/05 15:50:57 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/05 15:50:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/05 15:50:57 INFO Executor: Finished task 0.0 in stage 5.0 (TID 3). 1559 bytes result sent to driver\n",
      "24/02/05 15:50:57 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 18 ms on 80d73ccee89a (executor driver) (1/1)\n",
      "24/02/05 15:50:57 INFO DAGScheduler: ResultStage 5 (hasNext at Iterator.java:132) finished in 0.035 s\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/05 15:50:57 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "24/02/05 15:50:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Job 2 finished: hasNext at Iterator.java:132, took 0.043179 s\n",
      "24/02/05 15:50:57 INFO SparkContext: Starting job: hasNext at Iterator.java:132\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Got job 3 (hasNext at Iterator.java:132) with 1 output partitions\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Final stage: ResultStage 7 (hasNext at Iterator.java:132)\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Submitting ResultStage 7 (SparkReduceBy[1->1, id=45a2217f] MapPartitionsRDD[7] at map at SparkReduceByOperator.java:100), which has no missing parents\n",
      "24/02/05 15:50:57 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 5.4 KiB, free 2.1 GiB)\n",
      "24/02/05 15:50:57 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 2.1 GiB)\n",
      "24/02/05 15:50:57 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 80d73ccee89a:39579 (size: 2.9 KiB, free: 2.1 GiB)\n",
      "24/02/05 15:50:57 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (SparkReduceBy[1->1, id=45a2217f] MapPartitionsRDD[7] at map at SparkReduceByOperator.java:100) (first 15 tasks are for partitions Vector(3))\n",
      "24/02/05 15:50:57 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0\n",
      "24/02/05 15:50:57 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (80d73ccee89a, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/05 15:50:57 INFO Executor: Running task 0.0 in stage 7.0 (TID 4)\n",
      "24/02/05 15:50:57 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/05 15:50:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/05 15:50:57 INFO Executor: Finished task 0.0 in stage 7.0 (TID 4). 1562 bytes result sent to driver\n",
      "24/02/05 15:50:57 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 34 ms on 80d73ccee89a (executor driver) (1/1)\n",
      "24/02/05 15:50:57 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool \n",
      "24/02/05 15:50:57 INFO DAGScheduler: ResultStage 7 (hasNext at Iterator.java:132) finished in 0.091 s\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/05 15:50:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished\n",
      "24/02/05 15:50:57 INFO DAGScheduler: Job 3 finished: hasNext at Iterator.java:132, took 0.094163 s\n",
      "24/02/05 15:50:57 INFO SparkUI: Stopped Spark web UI at http://80d73ccee89a:4040\n",
      "24/02/05 15:50:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "24/02/05 15:50:57 INFO MemoryStore: MemoryStore cleared\n",
      "24/02/05 15:50:57 INFO BlockManager: BlockManager stopped\n",
      "24/02/05 15:50:57 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
      "24/02/05 15:50:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "24/02/05 15:50:57 INFO SparkContext: Successfully stopped SparkContext\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedText\">\n",
       "<pre><code><span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">result</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">Iterable</span></span>[(<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">Int</span></span>)] = <span style=\"color: yellow\"><span class=\"ansi-yellow-fg\">Buffer</span></span>(\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;bells&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;wind&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;qu&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;father&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;why&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;what&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;them&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;parturition&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;strangers&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;scheme&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;he&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;said&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;an&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;tears&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;living&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;the&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">3</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;his&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;body&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;this&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">3</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;currents&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;upon&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;boar&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;well&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;artificial&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;not&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">2</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;you&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;that&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">3</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;scaling&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;to&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">3</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;hours&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;and&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">5</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;entered&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>)\n",
       ")</code></pre>\n",
       "</div>"
      ],
      "text/plain": [
       "\u001b[36mresult\u001b[39m: \u001b[32mIterable\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mInt\u001b[39m)] = \u001b[33mBuffer\u001b[39m(\n",
       "  (\u001b[32m\"bells\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"wind\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"qu\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"father\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"why\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"what\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"them\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"parturition\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"strangers\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"scheme\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"he\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"said\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"an\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"tears\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"living\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"the\"\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  (\u001b[32m\"his\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"body\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"this\"\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  (\u001b[32m\"currents\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"upon\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"boar\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"well\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"artificial\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"not\"\u001b[39m, \u001b[32m2\u001b[39m),\n",
       "  (\u001b[32m\"you\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"that\"\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  (\u001b[32m\"scaling\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"to\"\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  (\u001b[32m\"hours\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"and\"\u001b[39m, \u001b[32m5\u001b[39m),\n",
       "  (\u001b[32m\"entered\"\u001b[39m, \u001b[32m1\u001b[39m)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var result = wordcount(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing WordCount in Flink\n",
    "\n",
    "Prepare the dependencies and set the Flink Plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                      \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.wayang.flink.Flink\n",
       "\u001b[39m\n",
       "\u001b[36mcontext\u001b[39m: \u001b[32mWayangContext\u001b[39m = org.apache.wayang.core.api.WayangContext@6350f087"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.wayang::wayang-flink:0.7.1`\n",
    "import org.apache.wayang.flink.Flink\n",
    "val context = new WayangContext().withPlugin(Flink.basicPlugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/05 15:51:10 INFO TypeExtractor: class scala.Tuple2 is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on \"Data Types & Serialization\" for details of the effect on performance.\n",
      "24/02/05 15:51:10 INFO ExecutionEnvironment: The job has 1 registered types and 0 default Kryo serializers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedText\">\n",
       "<pre><code><span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">result</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">Iterable</span></span>[(<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">Int</span></span>)] = <span style=\"color: yellow\"><span class=\"ansi-yellow-fg\">Buffer</span></span>(\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;tears&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;bells&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;scheme&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;father&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;why&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;upon&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;body&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;parturition&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;boar&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;that&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">3</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;currents&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;not&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">2</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;his&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;and&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">5</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;said&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;you&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;scaling&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;hours&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;living&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;qu&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;this&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">3</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;them&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;entered&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;strangers&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;an&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;the&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">3</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;artificial&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;what&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;well&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;to&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">3</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;he&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>),\n",
       "  (<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;wind&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1</span></span>)\n",
       ")</code></pre>\n",
       "</div>"
      ],
      "text/plain": [
       "\u001b[36mresult\u001b[39m: \u001b[32mIterable\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mInt\u001b[39m)] = \u001b[33mBuffer\u001b[39m(\n",
       "  (\u001b[32m\"tears\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"bells\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"scheme\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"father\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"why\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"upon\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"body\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"parturition\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"boar\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"that\"\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  (\u001b[32m\"currents\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"not\"\u001b[39m, \u001b[32m2\u001b[39m),\n",
       "  (\u001b[32m\"his\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"and\"\u001b[39m, \u001b[32m5\u001b[39m),\n",
       "  (\u001b[32m\"said\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"you\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"scaling\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"hours\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"living\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"qu\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"this\"\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  (\u001b[32m\"them\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"entered\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"strangers\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"an\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"the\"\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  (\u001b[32m\"artificial\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"what\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"well\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"to\"\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  (\u001b[32m\"he\"\u001b[39m, \u001b[32m1\u001b[39m),\n",
       "  (\u001b[32m\"wind\"\u001b[39m, \u001b[32m1\u001b[39m)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var result = wordcount(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Wordcount native implementation in the platforms\n",
    "\n",
    "One would have to implement the wordcount three times for three different platforms!\n",
    "\n",
    "### Java Stream Implementation\n",
    "\n",
    "```java    \n",
    "public class JavaWordCount {\n",
    "  public static void main(String args[]) {\n",
    "    long wordCount = 0;\n",
    "    Path textFilePath = Paths.get(args[0]);\n",
    "    try {\n",
    "      Stream<String> fileLines = \n",
    "      Files\n",
    "          .lines(textFilePath, Charset.defaultCharset())\n",
    "          .flatMap(line -> Arrays.stream(line.split(\"\\\\W+\")));\n",
    "          .filter(t -> t.length() != 0)\n",
    "          .collect(\n",
    "              Collectors.toConcurrentMap(\n",
    "                  w -> w, \n",
    "                  w -> 1,\n",
    "                  Integer::sum\n",
    "              )\n",
    "          );\n",
    "    } catch (IOException ioException) {\n",
    "      ioException.printStackTrace();\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Apache Flink Implementation\n",
    "\n",
    "```scala\n",
    "object FlinkWordCount {\n",
    "  def main(args: Array[String]) {\n",
    "    val env = ExecutionEnvironment.getExecutionEnvironment\n",
    "    \n",
    "    env.readTextFile(args(0))\n",
    "      .flatMap { _.split(\"\\\\W+\") \n",
    "      .filter(t -> t.length() != 0)\n",
    "      .map { (_, 1) }\n",
    "      .groupBy(0)\n",
    "      .sum(1)\n",
    "      .writeAsCsv(args(1), \"\\n\", \" \")\n",
    "                \n",
    "    env.execute(\"FlinkWordCount\")\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Apache Spark Implementation\n",
    "\n",
    "```scala\n",
    "object SparkWordCount {\n",
    "    def main(args: Array[String]) {\n",
    "      val conf = new SparkConf().setAppName(\"SparkWordCount\")\n",
    "      val sc = new SparkContext(conf)\n",
    "      sc.textFile(args(0))\n",
    "          .flatMap(line => line.split(\"\\\\W+\"))\n",
    "          .filter(word => word.length != 0 )\n",
    "          .map(word => (word, 1)) // implicit convertion to RDDPair\n",
    "          .reduceByKey{case (x, y) => x + y}\n",
    "          .saveAsTextFile(args(1))\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
