{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Example\n",
    "\n",
    "&emsp; Show capabilities processing iterative or recursive algorithms\n",
    "- Wayang API allows working with cycles\n",
    "- Enumerating process review if an operator was already processed\n",
    "\n",
    "&emsp; Review in detail how to work with Wayang API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Preparing dependancies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step imports the required modules to execute the code. All these packages come from the previous Maven Instalation\n",
    "\n",
    "```scala\n",
    "import $ivy.`ORGANIZATION:MODULE:VERSION` will bring the exact version\n",
    "import $ivy.`ORGANIZATION::MODULE:VERSION` the \"::\" bring the version of scala needed\n",
    "```\n",
    "\n",
    "The imported libraries are:\n",
    "\n",
    "Module | Java's | Scala's | Description\n",
    ":----- | -------------: | --------------: | :----------\n",
    "wayang-core | 8, 11 | 2.11, 2.12 | provides core data structures and the optimizer (required)\n",
    "wayang-basic | 8, 11 | 2.11, 2.12 | provides common operators and data types for your apps (recommended)\n",
    "wayang-api-scala-java | 8, 11 | 2.11, 2.12 | provides an easy-to-use Scala and Java API to assemble wayang plans (recommended)\n",
    "wayang-spark | 8, 11 | 2.11, 2.12 | adapters for [Apache Spark](https://spark.apache.org) processing platforms\n",
    "hadoop-common | 8,11 | - | Hadoop-commons is required because the lack of the Environment Variable **HADOOP_HOME**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                              \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                   \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                    \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                     \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                    \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                   \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                          \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                      \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/* Import Dependencies */\n",
    "import $ivy.`com.fasterxml.jackson.module:jackson-module-scala_2.12:2.10.2`\n",
    "import $ivy.`com.fasterxml.jackson.core:jackson-databind:2.10.2`\n",
    "import $ivy.`org.apache.wayang:wayang-core:0.7.1`\n",
    "import $ivy.`org.apache.wayang:wayang-basic:0.7.1`\n",
    "import $ivy.`org.apache.wayang:wayang-java:0.7.1`\n",
    "import $ivy.`org.apache.wayang:wayang-api-scala-java_2.12:0.7.1`\n",
    "import $ivy.`org.apache.wayang:wayang-spark_2.12:0.7.1`\n",
    "import $ivy.`org.apache.hadoop:hadoop-common:2.8.5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Import Class Section\n",
    "\n",
    "The classes that are required to run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.wayang.api._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.wayang.core.api.{Configuration, WayangContext}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.wayang.core.util.fs.FileSystems\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.wayang.core.function.ExecutionContext\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.wayang.core.function.FunctionDescriptor.ExtendedSerializableFunction\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.wayang.core.plugin.Plugin\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.wayang.spark.Spark\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.File\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util.{Collection => JavaCollection}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.JavaConversions._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Random\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.wayang.api._\n",
    "import org.apache.wayang.core.api.{Configuration, WayangContext}\n",
    "import org.apache.wayang.core.util.fs.FileSystems\n",
    "import org.apache.wayang.core.function.ExecutionContext\n",
    "import org.apache.wayang.core.function.FunctionDescriptor.ExtendedSerializableFunction\n",
    "import org.apache.wayang.core.plugin.Plugin\n",
    "import org.apache.wayang.spark.Spark\n",
    "import java.io.File\n",
    "import java.util.{Collection => JavaCollection}\n",
    "import scala.collection.JavaConversions._\n",
    "import scala.util.Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtrait\u001b[39m \u001b[36mPointLike\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mPoint\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mTaggedPoint\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mTaggedPointCounter\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "  * Represents objects with an x and a y coordinate.\n",
    "  */\n",
    "sealed trait PointLike {\n",
    "\n",
    "  /**\n",
    "    * @return the x coordinate\n",
    "    */\n",
    "  def x: Double\n",
    "\n",
    "  /**\n",
    "    * @return the y coordinate\n",
    "    */\n",
    "  def y: Double\n",
    "\n",
    "}\n",
    "\n",
    "/**\n",
    "  * Represents a two-dimensional point.\n",
    "  *\n",
    "  * @param x the x coordinate\n",
    "  * @param y the y coordinate\n",
    "  */\n",
    "case class Point(x: Double, y: Double) extends PointLike {\n",
    "\n",
    "  /**\n",
    "    * Calculates the Euclidean distance to another [[Point]].\n",
    "    *\n",
    "    * @param that the other [[PointLike]]\n",
    "    * @return the Euclidean distance\n",
    "    */\n",
    "  def distanceTo(that: PointLike) = {\n",
    "    val dx = this.x - that.x\n",
    "    val dy = this.y - that.y\n",
    "    math.sqrt(dx * dx + dy * dy)\n",
    "  }\n",
    "\n",
    "  override def toString: String = f\"($x%.2f, $y%.2f)\"\n",
    "}\n",
    "\n",
    "/**\n",
    "  * Represents a two-dimensional point with a centroid ID attached.\n",
    "  */\n",
    "case class TaggedPoint(x: Double, y: Double, centroidId: Int) extends PointLike {\n",
    "\n",
    "  /**\n",
    "    * Creates a [[Point]] from this instance.\n",
    "    *\n",
    "    * @return the [[Point]]\n",
    "    */\n",
    "  def toPoint = Point(x, y)\n",
    "\n",
    "}\n",
    "\n",
    "/**\n",
    "  * Represents a two-dimensional point with a centroid ID and a counter attached.\n",
    "  */\n",
    "case class TaggedPointCounter(x: Double, y: Double, centroidId: Int, count: Int = 1) extends PointLike {\n",
    "\n",
    "  def this(point: PointLike, centroidId: Int, count: Int) = this(point.x, point.y, centroidId, count)\n",
    "\n",
    "  /**\n",
    "    * Adds coordinates and counts of two instances.\n",
    "    *\n",
    "    * @param that the other instance\n",
    "    * @return the sum\n",
    "    */\n",
    "  def +(that: TaggedPointCounter) = TaggedPointCounter(this.x + that.x, this.y + that.y, this.centroidId, this.count + that.count)\n",
    "\n",
    "  /**\n",
    "    * Calculates the average of all added instances.\n",
    "    *\n",
    "    * @return a [[TaggedPoint]] reflecting the average\n",
    "    */\n",
    "  def average = TaggedPoint(x / count, y / count, centroidId)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mSelectNearestCentroid\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "  * UDF to select the closest centroid for a given [[Point]].\n",
    "  */\n",
    "class SelectNearestCentroid extends ExtendedSerializableFunction[Point, TaggedPointCounter] {\n",
    "\n",
    "  /** Keeps the broadcasted centroids. */\n",
    "  var centroids: JavaCollection[TaggedPoint] = _\n",
    "\n",
    "  override def open(executionCtx: ExecutionContext) = {\n",
    "    centroids = executionCtx.getBroadcast[TaggedPoint](\"centroids\")\n",
    "  }\n",
    "\n",
    "  override def apply(point: Point): TaggedPointCounter = {\n",
    "    var minDistance = Double.PositiveInfinity\n",
    "    var nearestCentroidId = -1\n",
    "    for (centroid <- centroids) {\n",
    "      val distance = point.distanceTo(centroid)\n",
    "      if (distance < minDistance) {\n",
    "        minDistance = distance\n",
    "        nearestCentroidId = centroid.centroidId\n",
    "      }\n",
    "    }\n",
    "    new TaggedPointCounter(point, nearestCentroidId, 1)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcreateRandomCentroids\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "* Creates random centroids.\n",
    "*\n",
    "* @param n      the number of centroids to create\n",
    "* @param random used to draw random coordinates\n",
    "* @return the centroids\n",
    "*/\n",
    "def createRandomCentroids(n: Int, random: Random = new Random()) =\n",
    "  // NOTE: The random cluster ID makes collisions during resurrection \n",
    "  //       less likely but in general permits ID collisions.\n",
    "  for (i <- 1 to n) yield TaggedPoint(random.nextGaussian(), random.nextGaussian(), random.nextInt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36minputFile\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"file:/home/jovyan/kmeans.txt\"\u001b[39m\n",
       "\u001b[36mk\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m100\u001b[39m\n",
       "\u001b[36miterations\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m10\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val inputFile = new File(\"files/kmeans.txt\").toURI().toString()\n",
    "val k = 100\n",
    "val iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedText\">\n",
       "<pre><code><span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">plugin</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">Plugin</span></span> = org.apache.wayang.spark.plugin.SparkBasicPlugin@39199148</code></pre>\n",
       "</div>"
      ],
      "text/plain": [
       "\u001b[36mplugin\u001b[39m: \u001b[32mPlugin\u001b[39m = org.apache.wayang.spark.plugin.SparkBasicPlugin@39199148"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var plugin: Plugin = Spark.basicPlugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mKmeans\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Kmeans(field0: Int, field1: Int) extends Serializable {\n",
    "    \n",
    "  def apply(plugin: Plugin, k: Int, inputFile: String, iterations: Int): Iterable[Point] = {\n",
    "    val context = new WayangContext().withPlugin(plugin)\n",
    "    val planBuilder = new PlanBuilder(context)\n",
    "      \n",
    "    // Read and parse the input file(s).\n",
    "    val points = planBuilder\n",
    "      .readTextFile(inputFile)\n",
    "      .filter( line => line.trim.nonEmpty && !line.startsWith(\"caseid\") )\n",
    "      .map { line =>\n",
    "        val fields = line.split(\",\")\n",
    "        Point(fields(field0).toDouble, fields(field1).toDouble)\n",
    "      }\n",
    "\n",
    "    // Create initial centroids.\n",
    "    val initialCentroids = planBuilder\n",
    "      .loadCollection(createRandomCentroids(k))\n",
    "\n",
    "    // Do the k-means loop.\n",
    "    val finalCentroids = initialCentroids.repeat(iterations, { currentCentroids =>\n",
    "      points\n",
    "        .mapJava(\n",
    "          new SelectNearestCentroid\n",
    "        )\n",
    "        .withBroadcast(currentCentroids, \"centroids\")\n",
    "        .reduceByKey(_.centroidId, _ + _)\n",
    "        .map(_.average)\n",
    "    })\n",
    "\n",
    "    // Collect the result.\n",
    "    finalCentroids\n",
    "      .map(_.toPoint)\n",
    "      .collect()\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.7.30/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "24/02/08 14:44:18 INFO SparkContext: Running Spark version 3.1.2\n",
      "24/02/08 14:44:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/02/08 14:44:18 INFO ResourceUtils: ==============================================================\n",
      "24/02/08 14:44:18 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "24/02/08 14:44:18 INFO ResourceUtils: ==============================================================\n",
      "24/02/08 14:44:18 INFO SparkContext: Submitted application: Wayang app\n",
      "24/02/08 14:44:18 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "24/02/08 14:44:18 INFO ResourceProfile: Limiting resource is cpu\n",
      "24/02/08 14:44:18 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "24/02/08 14:44:19 INFO SecurityManager: Changing view acls to: jovyan\n",
      "24/02/08 14:44:19 INFO SecurityManager: Changing modify acls to: jovyan\n",
      "24/02/08 14:44:19 INFO SecurityManager: Changing view acls groups to: \n",
      "24/02/08 14:44:19 INFO SecurityManager: Changing modify acls groups to: \n",
      "24/02/08 14:44:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jovyan); groups with view permissions: Set(); users  with modify permissions: Set(jovyan); groups with modify permissions: Set()\n",
      "24/02/08 14:44:19 INFO Utils: Successfully started service 'sparkDriver' on port 37431.\n",
      "24/02/08 14:44:19 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/02/08 14:44:19 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/02/08 14:44:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "24/02/08 14:44:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "24/02/08 14:44:19 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/02/08 14:44:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7e348c0a-22ba-4f60-9bea-bc919fe0385b\n",
      "24/02/08 14:44:19 INFO MemoryStore: MemoryStore started with capacity 2.1 GiB\n",
      "24/02/08 14:44:19 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "24/02/08 14:44:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "24/02/08 14:44:19 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://c262cdfc2874:4040\n",
      "24/02/08 14:44:19 INFO Executor: Starting executor ID driver on host c262cdfc2874\n",
      "24/02/08 14:44:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45427.\n",
      "24/02/08 14:44:20 INFO NettyBlockTransferService: Server created on c262cdfc2874:45427\n",
      "24/02/08 14:44:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "24/02/08 14:44:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c262cdfc2874, 45427, None)\n",
      "24/02/08 14:44:20 INFO BlockManagerMasterEndpoint: Registering block manager c262cdfc2874:45427 with 2.1 GiB RAM, BlockManagerId(driver, c262cdfc2874, 45427, None)\n",
      "24/02/08 14:44:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c262cdfc2874, 45427, None)\n",
      "24/02/08 14:44:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c262cdfc2874, 45427, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fs.s3.awsAccessKeyId\n",
      "fs.s3.awsSecretAccessKey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/08 14:44:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 175.9 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c262cdfc2874:45427 (size: 27.1 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:20 INFO SparkContext: Created broadcast 0 from textFile at SparkTextFileSource.java:70\n",
      "24/02/08 14:44:20 INFO FileInputFormat: Total input files to process : 1\n",
      "24/02/08 14:44:20 INFO SparkContext: Starting job: foreachPartition at SparkCacheOperator.java:62\n",
      "24/02/08 14:44:20 INFO DAGScheduler: Got job 0 (foreachPartition at SparkCacheOperator.java:62) with 1 output partitions\n",
      "24/02/08 14:44:20 INFO DAGScheduler: Final stage: ResultStage 0 (foreachPartition at SparkCacheOperator.java:62)\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at filter at RddChannel.java:91), which has no missing parents\n",
      "24/02/08 14:44:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.2 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c262cdfc2874:45427 (size: 4.1 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:21 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at filter at RddChannel.java:91) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/08 14:44:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "24/02/08 14:44:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4497 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "24/02/08 14:44:21 INFO HadoopRDD: Input split: file:/home/jovyan/kmeans.txt:0+1746\n",
      "24/02/08 14:44:21 INFO MemoryStore: Block rdd_4_0 stored as values in memory (estimated size 3.6 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:21 INFO BlockManagerInfo: Added rdd_4_0 in memory on c262cdfc2874:45427 (size: 3.6 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:21 INFO Executor: 1 block locks were not released by task 0.0 in stage 0.0 (TID 0)\n",
      "[rdd_4_0]\n",
      "24/02/08 14:44:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1009 bytes result sent to driver\n",
      "24/02/08 14:44:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 279 ms on c262cdfc2874 (executor driver) (1/1)\n",
      "24/02/08 14:44:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:21 INFO DAGScheduler: ResultStage 0 (foreachPartition at SparkCacheOperator.java:62) finished in 0.454 s\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/08 14:44:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Job 0 finished: foreachPartition at SparkCacheOperator.java:62, took 0.584287 s\n",
      "24/02/08 14:44:21 INFO SparkContext: Starting job: collect at SparkCollectOperator.java:65\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Got job 1 (collect at SparkCollectOperator.java:65) with 4 output partitions\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Final stage: ResultStage 1 (collect at SparkCollectOperator.java:65)\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at filter at RddChannel.java:91), which has no missing parents\n",
      "24/02/08 14:44:21 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.3 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:21 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:21 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on c262cdfc2874:45427 (size: 2.3 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:21 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at filter at RddChannel.java:91) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "24/02/08 14:44:21 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks resource profile 0\n",
      "24/02/08 14:44:21 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 5572 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:21 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "24/02/08 14:44:21 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2051 bytes result sent to driver\n",
      "24/02/08 14:44:21 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (c262cdfc2874, executor driver, partition 1, PROCESS_LOCAL, 5572 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:21 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)\n",
      "24/02/08 14:44:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 52 ms on c262cdfc2874 (executor driver) (1/4)\n",
      "24/02/08 14:44:21 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2051 bytes result sent to driver\n",
      "24/02/08 14:44:21 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (c262cdfc2874, executor driver, partition 2, PROCESS_LOCAL, 5572 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:21 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)\n",
      "24/02/08 14:44:21 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 20 ms on c262cdfc2874 (executor driver) (2/4)\n",
      "24/02/08 14:44:21 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2051 bytes result sent to driver\n",
      "24/02/08 14:44:21 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (c262cdfc2874, executor driver, partition 3, PROCESS_LOCAL, 5572 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:21 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)\n",
      "24/02/08 14:44:21 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 2051 bytes result sent to driver\n",
      "24/02/08 14:44:21 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 13 ms on c262cdfc2874 (executor driver) (3/4)\n",
      "24/02/08 14:44:21 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 36 ms on c262cdfc2874 (executor driver) (4/4)\n",
      "24/02/08 14:44:21 INFO DAGScheduler: ResultStage 1 (collect at SparkCollectOperator.java:65) finished in 0.159 s\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/08 14:44:21 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Job 1 finished: collect at SparkCollectOperator.java:65, took 0.176396 s\n",
      "24/02/08 14:44:21 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.6 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:21 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:21 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on c262cdfc2874:45427 (size: 3.2 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:21 INFO SparkContext: Created broadcast 3 from broadcast at SparkBroadcastOperator.java:64\n",
      "24/02/08 14:44:21 INFO SparkContext: Starting job: collect at SparkCollectOperator.java:65\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Registering RDD 9 (mapToPair at SparkReduceByOperator.java:95) as input to shuffle 0\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Got job 2 (collect at SparkCollectOperator.java:65) with 4 output partitions\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Final stage: ResultStage 3 (collect at SparkCollectOperator.java:65)\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)\n",
      "24/02/08 14:44:21 INFO DAGScheduler: Submitting ShuffleMapStage 2 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[9] at mapToPair at SparkReduceByOperator.java:95), which has no missing parents\n",
      "24/02/08 14:44:21 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 11.3 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:21 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on c262cdfc2874:45427 (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[9] at mapToPair at SparkReduceByOperator.java:95) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/08 14:44:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4486 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)\n",
      "24/02/08 14:44:22 INFO BlockManager: Found block rdd_4_0 locally\n",
      "24/02/08 14:44:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 106 ms on c262cdfc2874 (executor driver) (1/1)\n",
      "24/02/08 14:44:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:22 INFO DAGScheduler: ShuffleMapStage 2 (mapToPair at SparkReduceByOperator.java:95) finished in 0.186 s\n",
      "24/02/08 14:44:22 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/02/08 14:44:22 INFO DAGScheduler: running: Set()\n",
      "24/02/08 14:44:22 INFO DAGScheduler: waiting: Set(ResultStage 3)\n",
      "24/02/08 14:44:22 INFO DAGScheduler: failed: Set()\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[14] at filter at RddChannel.java:91), which has no missing parents\n",
      "24/02/08 14:44:22 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.4 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on c262cdfc2874:45427 (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at filter at RddChannel.java:91) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "24/02/08 14:44:22 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks resource profile 0\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 6) (c262cdfc2874, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:22 INFO Executor: Running task 2.0 in stage 3.0 (TID 6)\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms\n",
      "24/02/08 14:44:22 INFO BlockManagerInfo: Removed broadcast_1_piece0 on c262cdfc2874:45427 in memory (size: 4.1 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO BlockManagerInfo: Removed broadcast_2_piece0 on c262cdfc2874:45427 in memory (size: 2.3 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO Executor: Finished task 2.0 in stage 3.0 (TID 6). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 7) (c262cdfc2874, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 6) in 142 ms on c262cdfc2874 (executor driver) (1/4)\n",
      "24/02/08 14:44:22 INFO Executor: Running task 3.0 in stage 3.0 (TID 7)\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "24/02/08 14:44:22 INFO Executor: Finished task 3.0 in stage 3.0 (TID 7). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 8) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:22 INFO Executor: Running task 0.0 in stage 3.0 (TID 8)\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 7) in 86 ms on c262cdfc2874 (executor driver) (2/4)\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "24/02/08 14:44:22 INFO Executor: Finished task 0.0 in stage 3.0 (TID 8). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 9) (c262cdfc2874, executor driver, partition 1, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 8) in 18 ms on c262cdfc2874 (executor driver) (3/4)\n",
      "24/02/08 14:44:22 INFO Executor: Running task 1.0 in stage 3.0 (TID 9)\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "24/02/08 14:44:22 INFO Executor: Finished task 1.0 in stage 3.0 (TID 9). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 9) in 39 ms on c262cdfc2874 (executor driver) (4/4)\n",
      "24/02/08 14:44:22 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:22 INFO DAGScheduler: ResultStage 3 (collect at SparkCollectOperator.java:65) finished in 0.349 s\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/08 14:44:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Job 2 finished: collect at SparkCollectOperator.java:65, took 0.622494 s\n",
      "24/02/08 14:44:22 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 304.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 887.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on c262cdfc2874:45427 (size: 887.0 B, free: 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO SparkContext: Created broadcast 6 from broadcast at SparkBroadcastOperator.java:64\n",
      "24/02/08 14:44:22 INFO SparkContext: Starting job: collect at SparkCollectOperator.java:65\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Registering RDD 16 (mapToPair at SparkReduceByOperator.java:95) as input to shuffle 1\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Got job 3 (collect at SparkCollectOperator.java:65) with 4 output partitions\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Final stage: ResultStage 5 (collect at SparkCollectOperator.java:65)\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Submitting ShuffleMapStage 4 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[16] at mapToPair at SparkReduceByOperator.java:95), which has no missing parents\n",
      "24/02/08 14:44:22 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.3 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on c262cdfc2874:45427 (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[16] at mapToPair at SparkReduceByOperator.java:95) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/08 14:44:22 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4486 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:22 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)\n",
      "24/02/08 14:44:22 INFO BlockManager: Found block rdd_4_0 locally\n",
      "24/02/08 14:44:22 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1293 bytes result sent to driver\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 40 ms on c262cdfc2874 (executor driver) (1/1)\n",
      "24/02/08 14:44:22 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:22 INFO DAGScheduler: ShuffleMapStage 4 (mapToPair at SparkReduceByOperator.java:95) finished in 0.064 s\n",
      "24/02/08 14:44:22 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/02/08 14:44:22 INFO DAGScheduler: running: Set()\n",
      "24/02/08 14:44:22 INFO DAGScheduler: waiting: Set(ResultStage 5)\n",
      "24/02/08 14:44:22 INFO DAGScheduler: failed: Set()\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at filter at RddChannel.java:91), which has no missing parents\n",
      "24/02/08 14:44:22 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.4 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on c262cdfc2874:45427 (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at filter at RddChannel.java:91) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "24/02/08 14:44:22 INFO TaskSchedulerImpl: Adding task set 5.0 with 4 tasks resource profile 0\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 11) (c262cdfc2874, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:22 INFO Executor: Running task 2.0 in stage 5.0 (TID 11)\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:22 INFO Executor: Finished task 2.0 in stage 5.0 (TID 11). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 12) (c262cdfc2874, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 11) in 15 ms on c262cdfc2874 (executor driver) (1/4)\n",
      "24/02/08 14:44:22 INFO Executor: Running task 3.0 in stage 5.0 (TID 12)\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "24/02/08 14:44:22 INFO Executor: Finished task 3.0 in stage 5.0 (TID 12). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 13) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 12) in 45 ms on c262cdfc2874 (executor driver) (2/4)\n",
      "24/02/08 14:44:22 INFO Executor: Running task 0.0 in stage 5.0 (TID 13)\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "24/02/08 14:44:22 INFO Executor: Finished task 0.0 in stage 5.0 (TID 13). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 14) (c262cdfc2874, executor driver, partition 1, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:22 INFO Executor: Running task 1.0 in stage 5.0 (TID 14)\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 13) in 29 ms on c262cdfc2874 (executor driver) (3/4)\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "24/02/08 14:44:22 INFO Executor: Finished task 1.0 in stage 5.0 (TID 14). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 14) in 23 ms on c262cdfc2874 (executor driver) (4/4)\n",
      "24/02/08 14:44:22 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:22 INFO DAGScheduler: ResultStage 5 (collect at SparkCollectOperator.java:65) finished in 0.126 s\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/08 14:44:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Job 3 finished: collect at SparkCollectOperator.java:65, took 0.205944 s\n",
      "24/02/08 14:44:22 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 304.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 887.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on c262cdfc2874:45427 (size: 887.0 B, free: 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO SparkContext: Created broadcast 9 from broadcast at SparkBroadcastOperator.java:64\n",
      "24/02/08 14:44:22 INFO SparkContext: Starting job: collect at SparkCollectOperator.java:65\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Registering RDD 23 (mapToPair at SparkReduceByOperator.java:95) as input to shuffle 2\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Got job 4 (collect at SparkCollectOperator.java:65) with 4 output partitions\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Final stage: ResultStage 7 (collect at SparkCollectOperator.java:65)\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Submitting ShuffleMapStage 6 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[23] at mapToPair at SparkReduceByOperator.java:95), which has no missing parents\n",
      "24/02/08 14:44:22 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 11.3 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on c262cdfc2874:45427 (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[23] at mapToPair at SparkReduceByOperator.java:95) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/08 14:44:22 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 15) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4486 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:22 INFO Executor: Running task 0.0 in stage 6.0 (TID 15)\n",
      "24/02/08 14:44:22 INFO BlockManager: Found block rdd_4_0 locally\n",
      "24/02/08 14:44:22 INFO Executor: Finished task 0.0 in stage 6.0 (TID 15). 1293 bytes result sent to driver\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 15) in 39 ms on c262cdfc2874 (executor driver) (1/1)\n",
      "24/02/08 14:44:22 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:22 INFO DAGScheduler: ShuffleMapStage 6 (mapToPair at SparkReduceByOperator.java:95) finished in 0.062 s\n",
      "24/02/08 14:44:22 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/02/08 14:44:22 INFO DAGScheduler: running: Set()\n",
      "24/02/08 14:44:22 INFO DAGScheduler: waiting: Set(ResultStage 7)\n",
      "24/02/08 14:44:22 INFO DAGScheduler: failed: Set()\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[28] at filter at RddChannel.java:91), which has no missing parents\n",
      "24/02/08 14:44:22 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.4 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on c262cdfc2874:45427 (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:22 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 7 (MapPartitionsRDD[28] at filter at RddChannel.java:91) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "24/02/08 14:44:22 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks resource profile 0\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 16) (c262cdfc2874, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:22 INFO Executor: Running task 2.0 in stage 7.0 (TID 16)\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:22 INFO Executor: Finished task 2.0 in stage 7.0 (TID 16). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 17) (c262cdfc2874, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:22 INFO Executor: Running task 3.0 in stage 7.0 (TID 17)\n",
      "24/02/08 14:44:22 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 16) in 18 ms on c262cdfc2874 (executor driver) (1/4)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 3.0 in stage 7.0 (TID 17). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 18) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 17) in 18 ms on c262cdfc2874 (executor driver) (2/4)\n",
      "24/02/08 14:44:23 INFO Executor: Running task 0.0 in stage 7.0 (TID 18)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 0.0 in stage 7.0 (TID 18). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 19) (c262cdfc2874, executor driver, partition 1, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 1.0 in stage 7.0 (TID 19)\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 18) in 49 ms on c262cdfc2874 (executor driver) (3/4)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 1.0 in stage 7.0 (TID 19). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 19) in 17 ms on c262cdfc2874 (executor driver) (4/4)\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:23 INFO DAGScheduler: ResultStage 7 (collect at SparkCollectOperator.java:65) finished in 0.102 s\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Job 4 finished: collect at SparkCollectOperator.java:65, took 0.181773 s\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 304.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 887.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on c262cdfc2874:45427 (size: 887.0 B, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO SparkContext: Created broadcast 12 from broadcast at SparkBroadcastOperator.java:64\n",
      "24/02/08 14:44:23 INFO SparkContext: Starting job: collect at SparkCollectOperator.java:65\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Registering RDD 30 (mapToPair at SparkReduceByOperator.java:95) as input to shuffle 3\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Got job 5 (collect at SparkCollectOperator.java:65) with 4 output partitions\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Final stage: ResultStage 9 (collect at SparkCollectOperator.java:65)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting ShuffleMapStage 8 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[30] at mapToPair at SparkReduceByOperator.java:95), which has no missing parents\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 11.3 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on c262cdfc2874:45427 (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[30] at mapToPair at SparkReduceByOperator.java:95) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 20) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4486 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 0.0 in stage 8.0 (TID 20)\n",
      "24/02/08 14:44:23 INFO BlockManager: Found block rdd_4_0 locally\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 0.0 in stage 8.0 (TID 20). 1293 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 20) in 22 ms on c262cdfc2874 (executor driver) (1/1)\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:23 INFO DAGScheduler: ShuffleMapStage 8 (mapToPair at SparkReduceByOperator.java:95) finished in 0.047 s\n",
      "24/02/08 14:44:23 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/02/08 14:44:23 INFO DAGScheduler: running: Set()\n",
      "24/02/08 14:44:23 INFO DAGScheduler: waiting: Set(ResultStage 9)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: failed: Set()\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[35] at filter at RddChannel.java:91), which has no missing parents\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.4 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on c262cdfc2874:45427 (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[35] at filter at RddChannel.java:91) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks resource profile 0\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 21) (c262cdfc2874, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 2.0 in stage 9.0 (TID 21)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 2.0 in stage 9.0 (TID 21). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 22) (c262cdfc2874, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 21) in 15 ms on c262cdfc2874 (executor driver) (1/4)\n",
      "24/02/08 14:44:23 INFO Executor: Running task 3.0 in stage 9.0 (TID 22)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 3.0 in stage 9.0 (TID 22). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 23) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 0.0 in stage 9.0 (TID 23)\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 22) in 12 ms on c262cdfc2874 (executor driver) (2/4)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 0.0 in stage 9.0 (TID 23). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 24) (c262cdfc2874, executor driver, partition 1, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 23) in 8 ms on c262cdfc2874 (executor driver) (3/4)\n",
      "24/02/08 14:44:23 INFO Executor: Running task 1.0 in stage 9.0 (TID 24)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 1.0 in stage 9.0 (TID 24). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 24) in 7 ms on c262cdfc2874 (executor driver) (4/4)\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:23 INFO DAGScheduler: ResultStage 9 (collect at SparkCollectOperator.java:65) finished in 0.061 s\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Job 5 finished: collect at SparkCollectOperator.java:65, took 0.125873 s\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 304.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 887.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on c262cdfc2874:45427 (size: 887.0 B, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO SparkContext: Created broadcast 15 from broadcast at SparkBroadcastOperator.java:64\n",
      "24/02/08 14:44:23 INFO SparkContext: Starting job: collect at SparkCollectOperator.java:65\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Registering RDD 37 (mapToPair at SparkReduceByOperator.java:95) as input to shuffle 4\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Got job 6 (collect at SparkCollectOperator.java:65) with 4 output partitions\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Final stage: ResultStage 11 (collect at SparkCollectOperator.java:65)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting ShuffleMapStage 10 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[37] at mapToPair at SparkReduceByOperator.java:95), which has no missing parents\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 11.3 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on c262cdfc2874:45427 (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[37] at mapToPair at SparkReduceByOperator.java:95) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 25) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4486 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 0.0 in stage 10.0 (TID 25)\n",
      "24/02/08 14:44:23 INFO BlockManager: Found block rdd_4_0 locally\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 0.0 in stage 10.0 (TID 25). 1293 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 25) in 22 ms on c262cdfc2874 (executor driver) (1/1)\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:23 INFO DAGScheduler: ShuffleMapStage 10 (mapToPair at SparkReduceByOperator.java:95) finished in 0.040 s\n",
      "24/02/08 14:44:23 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/02/08 14:44:23 INFO DAGScheduler: running: Set()\n",
      "24/02/08 14:44:23 INFO DAGScheduler: waiting: Set(ResultStage 11)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: failed: Set()\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[42] at filter at RddChannel.java:91), which has no missing parents\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.4 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on c262cdfc2874:45427 (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 11 (MapPartitionsRDD[42] at filter at RddChannel.java:91) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks resource profile 0\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 26) (c262cdfc2874, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 2.0 in stage 11.0 (TID 26)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Removed broadcast_8_piece0 on c262cdfc2874:45427 in memory (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 2.0 in stage 11.0 (TID 26). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 27) (c262cdfc2874, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 3.0 in stage 11.0 (TID 27)\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 26) in 17 ms on c262cdfc2874 (executor driver) (1/4)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 3.0 in stage 11.0 (TID 27). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 28) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 27) in 11 ms on c262cdfc2874 (executor driver) (2/4)\n",
      "24/02/08 14:44:23 INFO Executor: Running task 0.0 in stage 11.0 (TID 28)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 0.0 in stage 11.0 (TID 28). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 29) (c262cdfc2874, executor driver, partition 1, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 28) in 8 ms on c262cdfc2874 (executor driver) (3/4)\n",
      "24/02/08 14:44:23 INFO Executor: Running task 1.0 in stage 11.0 (TID 29)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 1.0 in stage 11.0 (TID 29). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 29) in 7 ms on c262cdfc2874 (executor driver) (4/4)\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:23 INFO DAGScheduler: ResultStage 11 (collect at SparkCollectOperator.java:65) finished in 0.076 s\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Job 6 finished: collect at SparkCollectOperator.java:65, took 0.131405 s\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 304.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 887.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on c262cdfc2874:45427 (size: 887.0 B, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO SparkContext: Created broadcast 18 from broadcast at SparkBroadcastOperator.java:64\n",
      "24/02/08 14:44:23 INFO SparkContext: Starting job: collect at SparkCollectOperator.java:65\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Registering RDD 44 (mapToPair at SparkReduceByOperator.java:95) as input to shuffle 5\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Got job 7 (collect at SparkCollectOperator.java:65) with 4 output partitions\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Final stage: ResultStage 13 (collect at SparkCollectOperator.java:65)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting ShuffleMapStage 12 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[44] at mapToPair at SparkReduceByOperator.java:95), which has no missing parents\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Removed broadcast_4_piece0 on c262cdfc2874:45427 in memory (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 11.3 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on c262cdfc2874:45427 (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Removed broadcast_11_piece0 on c262cdfc2874:45427 in memory (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[44] at mapToPair at SparkReduceByOperator.java:95) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 30) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4486 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 0.0 in stage 12.0 (TID 30)\n",
      "24/02/08 14:44:23 INFO BlockManager: Found block rdd_4_0 locally\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Removed broadcast_13_piece0 on c262cdfc2874:45427 in memory (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 0.0 in stage 12.0 (TID 30). 1293 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 30) in 27 ms on c262cdfc2874 (executor driver) (1/1)\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:23 INFO DAGScheduler: ShuffleMapStage 12 (mapToPair at SparkReduceByOperator.java:95) finished in 0.063 s\n",
      "24/02/08 14:44:23 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/02/08 14:44:23 INFO DAGScheduler: running: Set()\n",
      "24/02/08 14:44:23 INFO DAGScheduler: waiting: Set(ResultStage 13)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: failed: Set()\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[49] at filter at RddChannel.java:91), which has no missing parents\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.4 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on c262cdfc2874:45427 (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 13 (MapPartitionsRDD[49] at filter at RddChannel.java:91) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks resource profile 0\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 31) (c262cdfc2874, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 2.0 in stage 13.0 (TID 31)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 2.0 in stage 13.0 (TID 31). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 32) (c262cdfc2874, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 3.0 in stage 13.0 (TID 32)\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 31) in 19 ms on c262cdfc2874 (executor driver) (1/4)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 3.0 in stage 13.0 (TID 32). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 33) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 0.0 in stage 13.0 (TID 33)\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 32) in 11 ms on c262cdfc2874 (executor driver) (2/4)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 0.0 in stage 13.0 (TID 33). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 34) (c262cdfc2874, executor driver, partition 1, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 33) in 17 ms on c262cdfc2874 (executor driver) (3/4)\n",
      "24/02/08 14:44:23 INFO Executor: Running task 1.0 in stage 13.0 (TID 34)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Removed broadcast_14_piece0 on c262cdfc2874:45427 in memory (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 1.0 in stage 13.0 (TID 34). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 34) in 20 ms on c262cdfc2874 (executor driver) (4/4)\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:23 INFO DAGScheduler: ResultStage 13 (collect at SparkCollectOperator.java:65) finished in 0.092 s\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Job 7 finished: collect at SparkCollectOperator.java:65, took 0.168103 s\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 304.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 887.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on c262cdfc2874:45427 (size: 887.0 B, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO SparkContext: Created broadcast 21 from broadcast at SparkBroadcastOperator.java:64\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Removed broadcast_5_piece0 on c262cdfc2874:45427 in memory (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO SparkContext: Starting job: collect at SparkCollectOperator.java:65\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Registering RDD 51 (mapToPair at SparkReduceByOperator.java:95) as input to shuffle 6\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Got job 8 (collect at SparkCollectOperator.java:65) with 4 output partitions\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Final stage: ResultStage 15 (collect at SparkCollectOperator.java:65)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting ShuffleMapStage 14 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[51] at mapToPair at SparkReduceByOperator.java:95), which has no missing parents\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 11.3 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Removed broadcast_10_piece0 on c262cdfc2874:45427 in memory (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on c262cdfc2874:45427 (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[51] at mapToPair at SparkReduceByOperator.java:95) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 35) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4486 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 0.0 in stage 14.0 (TID 35)\n",
      "24/02/08 14:44:23 INFO BlockManager: Found block rdd_4_0 locally\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 0.0 in stage 14.0 (TID 35). 1293 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 35) in 40 ms on c262cdfc2874 (executor driver) (1/1)\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:23 INFO DAGScheduler: ShuffleMapStage 14 (mapToPair at SparkReduceByOperator.java:95) finished in 0.096 s\n",
      "24/02/08 14:44:23 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/02/08 14:44:23 INFO DAGScheduler: running: Set()\n",
      "24/02/08 14:44:23 INFO DAGScheduler: waiting: Set(ResultStage 15)\n",
      "24/02/08 14:44:23 INFO DAGScheduler: failed: Set()\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[56] at filter at RddChannel.java:91), which has no missing parents\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 7.4 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Removed broadcast_7_piece0 on c262cdfc2874:45427 in memory (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on c262cdfc2874:45427 (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[56] at filter at RddChannel.java:91) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks resource profile 0\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 36) (c262cdfc2874, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 2.0 in stage 15.0 (TID 36)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 2.0 in stage 15.0 (TID 36). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 37) (c262cdfc2874, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 3.0 in stage 15.0 (TID 37)\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 36) in 30 ms on c262cdfc2874 (executor driver) (1/4)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 3.0 in stage 15.0 (TID 37). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 38) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 0.0 in stage 15.0 (TID 38)\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 37) in 14 ms on c262cdfc2874 (executor driver) (2/4)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 0.0 in stage 15.0 (TID 38). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 39) (c262cdfc2874, executor driver, partition 1, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:23 INFO Executor: Running task 1.0 in stage 15.0 (TID 39)\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 38) in 13 ms on c262cdfc2874 (executor driver) (3/4)\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:23 INFO Executor: Finished task 1.0 in stage 15.0 (TID 39). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:23 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 39) in 15 ms on c262cdfc2874 (executor driver) (4/4)\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:23 INFO DAGScheduler: ResultStage 15 (collect at SparkCollectOperator.java:65) finished in 0.075 s\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/08 14:44:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished\n",
      "24/02/08 14:44:23 INFO DAGScheduler: Job 8 finished: collect at SparkCollectOperator.java:65, took 0.190562 s\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 304.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 887.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on c262cdfc2874:45427 (size: 887.0 B, free: 2.1 GiB)\n",
      "24/02/08 14:44:23 INFO SparkContext: Created broadcast 24 from broadcast at SparkBroadcastOperator.java:64\n",
      "24/02/08 14:44:24 INFO SparkContext: Starting job: collect at SparkCollectOperator.java:65\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Registering RDD 58 (mapToPair at SparkReduceByOperator.java:95) as input to shuffle 7\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Got job 9 (collect at SparkCollectOperator.java:65) with 4 output partitions\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Final stage: ResultStage 17 (collect at SparkCollectOperator.java:65)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting ShuffleMapStage 16 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[58] at mapToPair at SparkReduceByOperator.java:95), which has no missing parents\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 11.3 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on c262cdfc2874:45427 (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[58] at mapToPair at SparkReduceByOperator.java:95) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 40) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4486 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:24 INFO Executor: Running task 0.0 in stage 16.0 (TID 40)\n",
      "24/02/08 14:44:24 INFO BlockManager: Found block rdd_4_0 locally\n",
      "24/02/08 14:44:24 INFO Executor: Finished task 0.0 in stage 16.0 (TID 40). 1293 bytes result sent to driver\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 40) in 16 ms on c262cdfc2874 (executor driver) (1/1)\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:24 INFO DAGScheduler: ShuffleMapStage 16 (mapToPair at SparkReduceByOperator.java:95) finished in 0.047 s\n",
      "24/02/08 14:44:24 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/02/08 14:44:24 INFO DAGScheduler: running: Set()\n",
      "24/02/08 14:44:24 INFO DAGScheduler: waiting: Set(ResultStage 17)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: failed: Set()\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[63] at filter at RddChannel.java:91), which has no missing parents\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.4 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on c262cdfc2874:45427 (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 17 (MapPartitionsRDD[63] at filter at RddChannel.java:91) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Adding task set 17.0 with 4 tasks resource profile 0\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 41) (c262cdfc2874, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:24 INFO Executor: Running task 2.0 in stage 17.0 (TID 41)\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:24 INFO Executor: Finished task 2.0 in stage 17.0 (TID 41). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 42) (c262cdfc2874, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 41) in 16 ms on c262cdfc2874 (executor driver) (1/4)\n",
      "24/02/08 14:44:24 INFO Executor: Running task 3.0 in stage 17.0 (TID 42)\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "24/02/08 14:44:24 INFO Executor: Finished task 3.0 in stage 17.0 (TID 42). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 43) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:24 INFO Executor: Running task 0.0 in stage 17.0 (TID 43)\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 42) in 32 ms on c262cdfc2874 (executor driver) (2/4)\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:24 INFO Executor: Finished task 0.0 in stage 17.0 (TID 43). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 44) (c262cdfc2874, executor driver, partition 1, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 43) in 16 ms on c262cdfc2874 (executor driver) (3/4)\n",
      "24/02/08 14:44:24 INFO Executor: Running task 1.0 in stage 17.0 (TID 44)\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:24 INFO Executor: Finished task 1.0 in stage 17.0 (TID 44). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 44) in 8 ms on c262cdfc2874 (executor driver) (4/4)\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:24 INFO DAGScheduler: ResultStage 17 (collect at SparkCollectOperator.java:65) finished in 0.085 s\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Job 9 finished: collect at SparkCollectOperator.java:65, took 0.144076 s\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 304.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 887.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on c262cdfc2874:45427 (size: 887.0 B, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO SparkContext: Created broadcast 27 from broadcast at SparkBroadcastOperator.java:64\n",
      "24/02/08 14:44:24 INFO SparkContext: Starting job: collect at SparkCollectOperator.java:65\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Registering RDD 65 (mapToPair at SparkReduceByOperator.java:95) as input to shuffle 8\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Got job 10 (collect at SparkCollectOperator.java:65) with 4 output partitions\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Final stage: ResultStage 19 (collect at SparkCollectOperator.java:65)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting ShuffleMapStage 18 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[65] at mapToPair at SparkReduceByOperator.java:95), which has no missing parents\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 11.3 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on c262cdfc2874:45427 (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[65] at mapToPair at SparkReduceByOperator.java:95) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 45) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4486 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:24 INFO Executor: Running task 0.0 in stage 18.0 (TID 45)\n",
      "24/02/08 14:44:24 INFO BlockManager: Found block rdd_4_0 locally\n",
      "24/02/08 14:44:24 INFO Executor: Finished task 0.0 in stage 18.0 (TID 45). 1293 bytes result sent to driver\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 45) in 14 ms on c262cdfc2874 (executor driver) (1/1)\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:24 INFO DAGScheduler: ShuffleMapStage 18 (mapToPair at SparkReduceByOperator.java:95) finished in 0.030 s\n",
      "24/02/08 14:44:24 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/02/08 14:44:24 INFO DAGScheduler: running: Set()\n",
      "24/02/08 14:44:24 INFO DAGScheduler: waiting: Set(ResultStage 19)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: failed: Set()\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[70] at filter at RddChannel.java:91), which has no missing parents\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 7.4 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on c262cdfc2874:45427 (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 19 (MapPartitionsRDD[70] at filter at RddChannel.java:91) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Adding task set 19.0 with 4 tasks resource profile 0\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 46) (c262cdfc2874, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:24 INFO Executor: Running task 2.0 in stage 19.0 (TID 46)\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:24 INFO Executor: Finished task 2.0 in stage 19.0 (TID 46). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Starting task 3.0 in stage 19.0 (TID 47) (c262cdfc2874, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 46) in 8 ms on c262cdfc2874 (executor driver) (1/4)\n",
      "24/02/08 14:44:24 INFO Executor: Running task 3.0 in stage 19.0 (TID 47)\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Removed broadcast_17_piece0 on c262cdfc2874:45427 in memory (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "24/02/08 14:44:24 INFO Executor: Finished task 3.0 in stage 19.0 (TID 47). 1735 bytes result sent to driver\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 48) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Finished task 3.0 in stage 19.0 (TID 47) in 31 ms on c262cdfc2874 (executor driver) (2/4)\n",
      "24/02/08 14:44:24 INFO Executor: Running task 0.0 in stage 19.0 (TID 48)\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:24 INFO Executor: Finished task 0.0 in stage 19.0 (TID 48). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 49) (c262cdfc2874, executor driver, partition 1, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:24 INFO Executor: Running task 1.0 in stage 19.0 (TID 49)\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 48) in 9 ms on c262cdfc2874 (executor driver) (3/4)\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:24 INFO Executor: Finished task 1.0 in stage 19.0 (TID 49). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 49) in 7 ms on c262cdfc2874 (executor driver) (4/4)\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:24 INFO DAGScheduler: ResultStage 19 (collect at SparkCollectOperator.java:65) finished in 0.102 s\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Job 10 finished: collect at SparkCollectOperator.java:65, took 0.145038 s\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 304.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 887.0 B, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on c262cdfc2874:45427 (size: 887.0 B, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO SparkContext: Created broadcast 30 from broadcast at SparkBroadcastOperator.java:64\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Removed broadcast_23_piece0 on c262cdfc2874:45427 in memory (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO SparkContext: Starting job: hasNext at Iterator.java:132\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Registering RDD 72 (mapToPair at SparkReduceByOperator.java:95) as input to shuffle 9\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Got job 11 (hasNext at Iterator.java:132) with 1 output partitions\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Final stage: ResultStage 21 (hasNext at Iterator.java:132)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting ShuffleMapStage 20 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[72] at mapToPair at SparkReduceByOperator.java:95), which has no missing parents\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 11.3 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on c262cdfc2874:45427 (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (SparkReduceBy[1->1, id=1f3627a4] MapPartitionsRDD[72] at mapToPair at SparkReduceByOperator.java:95) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 50) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4486 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:24 INFO Executor: Running task 0.0 in stage 20.0 (TID 50)\n",
      "24/02/08 14:44:24 INFO BlockManager: Found block rdd_4_0 locally\n",
      "24/02/08 14:44:24 INFO Executor: Finished task 0.0 in stage 20.0 (TID 50). 1293 bytes result sent to driver\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Removed broadcast_26_piece0 on c262cdfc2874:45427 in memory (size: 3.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 50) in 26 ms on c262cdfc2874 (executor driver) (1/1)\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:24 INFO DAGScheduler: ShuffleMapStage 20 (mapToPair at SparkReduceByOperator.java:95) finished in 0.032 s\n",
      "24/02/08 14:44:24 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/02/08 14:44:24 INFO DAGScheduler: running: Set()\n",
      "24/02/08 14:44:24 INFO DAGScheduler: waiting: Set(ResultStage 21)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: failed: Set()\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting ResultStage 21 (SparkMap[1->1, id=6eff71fb] MapPartitionsRDD[78] at map at SparkMapOperator.java:87), which has no missing parents\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 7.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on c262cdfc2874:45427 (size: 3.8 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (SparkMap[1->1, id=6eff71fb] MapPartitionsRDD[78] at map at SparkMapOperator.java:87) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 51) (c262cdfc2874, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:24 INFO Executor: Running task 0.0 in stage 21.0 (TID 51)\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:24 INFO Executor: Finished task 0.0 in stage 21.0 (TID 51). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 51) in 6 ms on c262cdfc2874 (executor driver) (1/1)\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:24 INFO DAGScheduler: ResultStage 21 (hasNext at Iterator.java:132) finished in 0.023 s\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Job 11 finished: hasNext at Iterator.java:132, took 0.064317 s\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Removed broadcast_25_piece0 on c262cdfc2874:45427 in memory (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO SparkContext: Starting job: hasNext at Iterator.java:132\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Got job 12 (hasNext at Iterator.java:132) with 1 output partitions\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Final stage: ResultStage 23 (hasNext at Iterator.java:132)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting ResultStage 23 (SparkMap[1->1, id=6eff71fb] MapPartitionsRDD[78] at map at SparkMapOperator.java:87), which has no missing parents\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on c262cdfc2874:45427 (size: 3.8 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (SparkMap[1->1, id=6eff71fb] MapPartitionsRDD[78] at map at SparkMapOperator.java:87) (first 15 tasks are for partitions Vector(1))\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 52) (c262cdfc2874, executor driver, partition 1, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:24 INFO Executor: Running task 0.0 in stage 23.0 (TID 52)\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:24 INFO Executor: Finished task 0.0 in stage 23.0 (TID 52). 1353 bytes result sent to driver\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 52) in 16 ms on c262cdfc2874 (executor driver) (1/1)\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:24 INFO DAGScheduler: ResultStage 23 (hasNext at Iterator.java:132) finished in 0.054 s\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Job 12 finished: hasNext at Iterator.java:132, took 0.061855 s\n",
      "24/02/08 14:44:24 INFO SparkContext: Starting job: hasNext at Iterator.java:132\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Got job 13 (hasNext at Iterator.java:132) with 1 output partitions\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Final stage: ResultStage 25 (hasNext at Iterator.java:132)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting ResultStage 25 (SparkMap[1->1, id=6eff71fb] MapPartitionsRDD[78] at map at SparkMapOperator.java:87), which has no missing parents\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 7.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on c262cdfc2874:45427 (size: 3.8 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (SparkMap[1->1, id=6eff71fb] MapPartitionsRDD[78] at map at SparkMapOperator.java:87) (first 15 tasks are for partitions Vector(2))\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 53) (c262cdfc2874, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:24 INFO Executor: Running task 0.0 in stage 25.0 (TID 53)\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:24 INFO Executor: Finished task 0.0 in stage 25.0 (TID 53). 1755 bytes result sent to driver\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 53) in 20 ms on c262cdfc2874 (executor driver) (1/1)\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:24 INFO DAGScheduler: ResultStage 25 (hasNext at Iterator.java:132) finished in 0.031 s\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Job 13 finished: hasNext at Iterator.java:132, took 0.041168 s\n",
      "24/02/08 14:44:24 INFO SparkContext: Starting job: hasNext at Iterator.java:132\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Got job 14 (hasNext at Iterator.java:132) with 1 output partitions\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Final stage: ResultStage 27 (hasNext at Iterator.java:132)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting ResultStage 27 (SparkMap[1->1, id=6eff71fb] MapPartitionsRDD[78] at map at SparkMapOperator.java:87), which has no missing parents\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 7.7 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on c262cdfc2874:45427 (size: 3.8 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1388\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (SparkMap[1->1, id=6eff71fb] MapPartitionsRDD[78] at map at SparkMapOperator.java:87) (first 15 tasks are for partitions Vector(3))\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 54) (c262cdfc2874, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "24/02/08 14:44:24 INFO Executor: Running task 0.0 in stage 27.0 (TID 54)\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "24/02/08 14:44:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/08 14:44:24 INFO Executor: Finished task 0.0 in stage 27.0 (TID 54). 1712 bytes result sent to driver\n",
      "24/02/08 14:44:24 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 54) in 8 ms on c262cdfc2874 (executor driver) (1/1)\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool \n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Removed broadcast_22_piece0 on c262cdfc2874:45427 in memory (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO DAGScheduler: ResultStage 27 (hasNext at Iterator.java:132) finished in 0.025 s\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/08 14:44:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished\n",
      "24/02/08 14:44:24 INFO DAGScheduler: Job 14 finished: hasNext at Iterator.java:132, took 0.027912 s\n",
      "24/02/08 14:44:24 INFO MapPartitionsRDD: Removing RDD 4 from persistence list\n",
      "24/02/08 14:44:24 INFO BlockManager: Removing RDD 4\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Removed broadcast_19_piece0 on c262cdfc2874:45427 in memory (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:24 INFO BlockManagerInfo: Removed broadcast_16_piece0 on c262cdfc2874:45427 in memory (size: 5.7 KiB, free: 2.1 GiB)\n",
      "24/02/08 14:44:25 INFO BlockManagerInfo: Removed broadcast_20_piece0 on c262cdfc2874:45427 in memory (size: 3.7 KiB, free: 2.1 GiB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedText\">\n",
       "<pre><code><span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">result</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">Iterable</span></span>[<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">Point</span></span>] = <span style=\"color: yellow\"><span class=\"ansi-yellow-fg\">Buffer</span></span>(\n",
       "  <span style=\"color: yellow\"><span class=\"ansi-yellow-fg\">Point</span></span>(<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">5.330318545454546</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">18.470108909090907</span></span>),\n",
       "  <span style=\"color: yellow\"><span class=\"ansi-yellow-fg\">Point</span></span>(<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">13.559882444444442</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">21.626612444444447</span></span>)\n",
       ")</code></pre>\n",
       "</div>"
      ],
      "text/plain": [
       "\u001b[36mresult\u001b[39m: \u001b[32mIterable\u001b[39m[\u001b[32mPoint\u001b[39m] = \u001b[33mBuffer\u001b[39m(\n",
       "  \u001b[33mPoint\u001b[39m(\u001b[32m5.330318545454546\u001b[39m, \u001b[32m18.470108909090907\u001b[39m),\n",
       "  \u001b[33mPoint\u001b[39m(\u001b[32m13.559882444444442\u001b[39m, \u001b[32m21.626612444444447\u001b[39m)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var result = new Kmeans(0, 1).apply(plugin, k, inputFile, iterations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
